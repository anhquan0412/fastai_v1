{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_001b import *\n",
    "import sys, PIL, matplotlib.pyplot as plt, itertools, math, random, collections, torch\n",
    "import scipy.stats, scipy.special\n",
    "\n",
    "from enum import Enum, IntEnum\n",
    "from torch import tensor, FloatTensor, LongTensor, ByteTensor, DoubleTensor, HalfTensor, ShortTensor\n",
    "from operator import itemgetter, attrgetter\n",
    "from numpy import cos, sin, tan, tanh, log, exp\n",
    "\n",
    "from functools import reduce\n",
    "from collections import defaultdict, abc, namedtuple, Iterable\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR subset data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to view our data to check if everything is how we expect it to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "PATH = DATA_PATH/'cifar10_dog_air'\n",
    "TRAIN_PATH = PATH/'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_fn = list((TRAIN_PATH/'dog').iterdir())[0]\n",
    "dog_image = Image.open(dog_fn)\n",
    "dog_image.resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_fn = list((TRAIN_PATH/'airplane').iterdir())[0]\n",
    "air_image = Image.open(air_fn)\n",
    "air_image.resize((256,256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Dataset/Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a Dataset class for our image files. A Dataset class needs to have two functions: length and get-item. Our FilesDataset additionally gets the image files from their respective directories and transforms them to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_classes(folder):\n",
    "    classes = [d for d in folder.iterdir()\n",
    "               if d.is_dir() and not d.name.startswith('.')]\n",
    "    assert(len(classes)>0)\n",
    "    return sorted(classes, key=lambda d: d.name)\n",
    "\n",
    "def get_image_files(c):\n",
    "    return [o for o in list(c.iterdir())\n",
    "            if not o.name.startswith('.') and not o.is_dir()]\n",
    "\n",
    "def pil2tensor(image):\n",
    "    arr = torch.ByteTensor(torch.ByteStorage.from_buffer(image.tobytes()))\n",
    "    arr = arr.view(image.size[1], image.size[0], -1)\n",
    "    arr = arr.permute(2,0,1)\n",
    "    return arr.float().div_(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FilesDataset(Dataset):\n",
    "    def __init__(self, folder, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        return pil2tensor(x),self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FilesDataset(PATH/'train')\n",
    "valid_ds = FilesDataset(PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def image2np(image): return image.cpu().permute(1,2,0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[0]\n",
    "plt.imshow(image2np(x))\n",
    "print(train_ds.classes[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_ds, valid_ds, bs=bs)\n",
    "len(data.train_dl), len(data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_image(img, ax=None, figsize=(3,3), hide_axis=True):\n",
    "    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image2np(img))\n",
    "    if hide_axis: ax.axis('off')\n",
    "\n",
    "def show_image_batch(dl, classes, rows=None, figsize=(12,15)):\n",
    "    x,y = next(iter(dl))\n",
    "    if rows is None: rows = int(math.sqrt(len(x)))\n",
    "    show_images(x[:rows*rows],y[:rows*rows],rows, classes)\n",
    "\n",
    "def show_images(x,y,rows, classes, figsize=(9,9)):\n",
    "    fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        show_image(x[i], ax)\n",
    "        ax.set_title(classes[y[i]])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_batch(data.train_dl, train_ds.classes, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going augment our data to increase our training set. We will start by changing the brightness and contrast of our images.\n",
    "\n",
    "Brightness is computed by taking the logit of the change and adding it to the logit of the images pixels. Finally we take the sigmoid of the result.\n",
    "\n",
    "Contrast is computed by simply multiplying pixel values by the scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def logit(x): return (x/(1-x)).log()\n",
    "def logit_(x): return (x.div_(1-x)).log_()\n",
    "\n",
    "def brightness(x, change): return x.add_(scipy.special.logit(change))\n",
    "def contrast(x, scale): return x.mul_(scale)\n",
    "\n",
    "def apply_lighting(func): return lambda x: func(logit_(x)).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_contrast(scale): return apply_lighting(partial(contrast, scale=scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lambda: train_ds[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "\n",
    "show_image(x(), axes[0])\n",
    "show_image(apply_contrast(1.0)(x()), axes[1])\n",
    "show_image(apply_contrast(0.5)(x()), axes[2])\n",
    "show_image(apply_contrast(2.0)(x()), axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_brightness(change):\n",
    "    return apply_lighting(partial(brightness, change=change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "\n",
    "show_image(x(), axes[0])\n",
    "show_image(apply_brightness(0.5)(x()), axes[1])\n",
    "show_image(apply_brightness(0.8)(x()), axes[2])\n",
    "show_image(apply_brightness(0.2)(x()), axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def listify(p=None, q=None):\n",
    "    if p is None: p=[]\n",
    "    elif not isinstance(p, Iterable): p=[p]\n",
    "    n = q if type(q)==int else 1 if q is None else len(q)\n",
    "    if len(p)==1: p = p * n\n",
    "    return p\n",
    "\n",
    "def compose(funcs):\n",
    "    def _inner(x, *args, **kwargs):\n",
    "        for f in funcs: x = f(x, *args, **kwargs)\n",
    "        return x\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_brightness_contrast(scale_contrast, change_brightness):\n",
    "    return apply_lighting(compose([\n",
    "        partial(contrast, scale=scale_contrast),\n",
    "        partial(brightness, change=change_brightness)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "\n",
    "show_image(apply_brightness_contrast(0.75, 0.7)(x()), axes[0])\n",
    "show_image(apply_brightness_contrast(1.3,  0.3)(x()), axes[1])\n",
    "show_image(apply_brightness_contrast(1.3,  0.7)(x()), axes[2])\n",
    "show_image(apply_brightness_contrast(0.75, 0.3)(x()), axes[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random lighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will make our previous transforms random since we are interested in automatizing the transforms pipeline. We will achieve this by making our parameters stochastic with a specific distribution: uniform for brightness and log_uniform for contrast. **TODO WHY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def uniform(low, high, size=None):\n",
    "    return random.uniform(low,high) if size is None else torch.FloatTensor(size).uniform_(low,high)\n",
    "\n",
    "def log_uniform(low, high, size=None):\n",
    "    res = uniform(log(low), log(high), size)\n",
    "    return exp(res) if size is None else res.exp_()\n",
    "\n",
    "def rand_bool(p, size=None): return uniform(0,1,size)<p\n",
    "\n",
    "TfmType = IntEnum('TfmType', 'Start Affine Coord Pixel Lighting')\n",
    "\n",
    "def brightness(x, change: uniform) -> TfmType.Lighting:\n",
    "    return x.add_(scipy.special.logit(change))\n",
    "\n",
    "def contrast(x, scale: log_uniform) -> TfmType.Lighting:\n",
    "    return x.mul_(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.gmean([log_uniform(0.5,2.0) for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import inspect\n",
    "\n",
    "def get_default_args(func):\n",
    "    return {k: v.default\n",
    "            for k, v in inspect.signature(func).parameters.items()\n",
    "            if v.default is not inspect.Parameter.empty}\n",
    "\n",
    "def resolve_args(func, **kwargs):\n",
    "    kwargs.pop('p', None)\n",
    "    def_args = get_default_args(func)\n",
    "    for k,v in func.__annotations__.items():\n",
    "        if k == 'return': continue\n",
    "        if not k in kwargs and k in def_args:\n",
    "            kwargs[k] = def_args[k]\n",
    "        else:\n",
    "            arg = listify(kwargs.get(k, 1))\n",
    "            kwargs[k] = v(*arg)\n",
    "    return kwargs\n",
    "\n",
    "def noop(x=None, *args, **kwargs): return x\n",
    "\n",
    "class Transform():\n",
    "    def __init__(self, func, **kwargs):\n",
    "        self.func,self.kw = func,kwargs\n",
    "        self.tfm_type = self.func.__annotations__['return']\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{self.func.__name__}_tfm->{self.tfm_type.name}; {self.kw}'\n",
    "    \n",
    "    def __call__(self):\n",
    "        if 'p' in self.kw and not rand_bool(self.kw['p']): return noop\n",
    "        kwargs = resolve_args(self.func, **self.kw)\n",
    "        return partial(self.func, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_args(brightness, change=(0.25,0.75),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_tfm = partial(Transform, contrast)\n",
    "tfm = contrast_tfm(scale=(0.3,3))\n",
    "tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the same\n",
    "tfm = tfm()\n",
    "\n",
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_lighting(tfm)(x()), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = contrast_tfm(scale=(0.3,3), p=0.5)\n",
    "\n",
    "# different\n",
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_lighting(tfm())(x()), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorator and composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continue from here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reg_partial(cl, func):\n",
    "    setattr(sys.modules[func.__module__], f'{func.__name__}_tfm', partial(cl,func))\n",
    "    return func\n",
    "\n",
    "def reg_transform(func): return reg_partial(Transform, func)\n",
    "\n",
    "def resolve_tfms(tfms): return [f() for f in listify(tfms)]\n",
    "\n",
    "@reg_transform\n",
    "def brightness(x, change: uniform) -> TfmType.Lighting:  return x.add_(scipy.special.logit(change))\n",
    "\n",
    "@reg_transform\n",
    "def contrast(x, scale: log_uniform) -> TfmType.Lighting: return x.mul_(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tfms(tfms):\n",
    "    func = apply_lighting(compose(resolve_tfms(tfms)))\n",
    "    return lambda x: func(x.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_ds[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [contrast_tfm(scale=(0.3,3.0), p=0.5),\n",
    "        brightness_tfm(change=(0.35,0.65), p=0.5)]\n",
    "\n",
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_tfms(tfms)(x), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(2,4, figsize=(12,6))\n",
    "for i in range(4):\n",
    "    tfm = apply_tfms(tfms)\n",
    "    show_image(tfm(x), axes[0][i])\n",
    "    show_image(tfm(x), axes[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def grid_sample_nearest(input, coords, padding_mode='zeros'):\n",
    "    if padding_mode=='border': coords.clamp(-1,1)\n",
    "    bs,ch,h,w = input.size()\n",
    "    sz = torch.tensor([w,h]).float()[None,None]\n",
    "    coords.add_(1).mul_(sz/2)\n",
    "    coords = coords[0].round_().long()\n",
    "    if padding_mode=='zeros':\n",
    "        mask = (coords[...,0] < 0) + (coords[...,1] < 0) + (coords[...,0] >= w) + (coords[...,1] >= h)\n",
    "        mask.clamp_(0,1)\n",
    "    coords[...,0].clamp_(0,w-1)\n",
    "    coords[...,1].clamp_(0,h-1)\n",
    "    result = input[...,coords[...,1],coords[...,0]]\n",
    "    if padding_mode=='zeros': result[...,mask] = result[...,mask].zero_()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def grid_sample(x, coords, mode='bilinear', padding_mode='reflect'):\n",
    "    if mode=='nearest': return grid_sample_nearest(x[None], coords, padding_mode)[0]\n",
    "    if padding_mode=='reflect': # Reflect padding isn't implemented in grid_sample yet\n",
    "        coords[coords < -1] = coords[coords < -1].mul_(-1).add_(-2)\n",
    "        coords[coords > 1] = coords[coords > 1].mul_(-1).add_(2)\n",
    "        padding_mode='zeros'\n",
    "    return F.grid_sample(x[None], coords, mode=mode, padding_mode=padding_mode)[0]\n",
    "\n",
    "def affine_grid(x, matrix, size=None):\n",
    "    if size is None: size = x.size()\n",
    "    elif isinstance(size, int): size=(x.size(0), size, size)\n",
    "    return F.affine_grid(matrix[None,:2], torch.Size((1,)+size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(degrees):\n",
    "    angle = degrees * math.pi / 180\n",
    "    return [[cos(angle), -sin(angle), 0.],\n",
    "            [sin(angle),  cos(angle), 0.],\n",
    "            [0.        ,  0.        , 1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = rotate(30)\n",
    "m = x.new_tensor(m)\n",
    "c = affine_grid(x, m)\n",
    "img2 = grid_sample(x, c, padding_mode='zeros')\n",
    "show_image(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply_affine(m=None, func=None):\n",
    "    if m is None: m=torch.eye(3)\n",
    "    def _inner(img, size=None, **kwargs):\n",
    "        c = affine_grid(img,  img.new_tensor(m), size=size)\n",
    "        if func is not None: c = func(c)\n",
    "        return grid_sample(img, c, **kwargs)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(scale: uniform, row_pct = 0.5, col_pct = 0.5):\n",
    "    s = 1-1/scale\n",
    "    col_c = s * (2*col_pct - 1)\n",
    "    row_c = s * (2*row_pct - 1)\n",
    "    return [[1/scale, 0,       col_c],\n",
    "            [0,       1/scale, row_c],\n",
    "            [0,       0,       1.    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_affine(zoom(0.6))(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_affine(zoom(0.6))(x, padding_mode='zeros'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_affine(zoom(2, 0.2, 0.2))(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def affines_mat(matrices=None):\n",
    "    if matrices is None: matrices=[]\n",
    "    matrices = [FloatTensor(m) for m in matrices if m is not None]\n",
    "    return reduce(torch.matmul, matrices, torch.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = apply_affine(rotate(30))(x)\n",
    "img2 = apply_affine(zoom(1.6))(img2)\n",
    "show_image(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = affines_mat([zoom(1.6), rotate(30)])\n",
    "show_image(apply_affine(c)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = affines_mat([zoom(1.6, 0.8, 0.2), rotate(30)])\n",
    "show_image(apply_affine(c)(x, size=48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = affines_mat([zoom(1.6, 0.8, 0.2), rotate(30)])\n",
    "show_image(apply_affine(c)(x, size=24), hide_axis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = affines_mat([zoom(1.6, 0.8, 0.2), rotate(30)])\n",
    "show_image(apply_affine(c)(x, size=48, mode='nearest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = affines_mat([zoom(1.6)])\n",
    "show_image(apply_affine(c)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = affines_mat()\n",
    "show_image(apply_affine(c)(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AffineTransform(Transform):\n",
    "    def __call__(self): return super().__call__()()\n",
    "\n",
    "def dict_groupby(iterable, key=None):\n",
    "    return {k:list(v) for k,v in itertools.groupby(sorted(iterable, key=key), key=key)}\n",
    "\n",
    "def reg_affine(func): return reg_partial(AffineTransform, func)\n",
    "\n",
    "def apply_tfms(tfms):\n",
    "    grouped_tfms = dict_groupby(listify(tfms), lambda o: o.tfm_type)\n",
    "    start_tfms,affine_tfms,coord_tfms,pixel_tfms,lighting_tfms = [\n",
    "        resolve_tfms(grouped_tfms.get(o)) for o in TfmType]\n",
    "    lighting_func = apply_lighting(compose(lighting_tfms))\n",
    "    affine_func = apply_affine(affines_mat(affine_tfms), func=compose(coord_tfms))\n",
    "    start_func = compose(start_tfms)\n",
    "    pixel_func = compose(pixel_tfms)\n",
    "    return lambda x, **kwargs: pixel_func(lighting_func(affine_func(start_func(x.clone()), **kwargs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@reg_affine\n",
    "def rotate(degrees: uniform) -> TfmType.Affine:\n",
    "    angle = degrees * math.pi / 180\n",
    "    return [[cos(angle), -sin(angle), 0.],\n",
    "            [sin(angle),  cos(angle), 0.],\n",
    "            [0.        ,  0.        , 1.]]\n",
    "\n",
    "@reg_affine\n",
    "def zoom(scale: uniform = 1.0, row_pct:uniform = 0.5, col_pct:uniform = 0.5) -> TfmType.Affine:\n",
    "    s = 1-1/scale\n",
    "    col_c = s * (2*col_pct - 1)\n",
    "    row_c = s * (2*row_pct - 1)\n",
    "    return [[1/scale, 0,       col_c],\n",
    "            [0,       1/scale, row_c],\n",
    "            [0,       0,       1.    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [rotate_tfm(degrees=(-45,45.), p=0.75),\n",
    "        zoom_tfm(scale=(0.5,2.0), p=0.75)]\n",
    "\n",
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_tfms(tfms)(x), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [rotate_tfm(degrees=(-45,45.), p=0.75),\n",
    "        zoom_tfm(scale=(1.0,2.0), row_pct=(0,1.), col_pct=(0,1.))]\n",
    "\n",
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_tfms(tfms)(x, size=64, padding_mode='zeros'), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coord and pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jitter / flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@reg_transform\n",
    "def jitter(x, magnitude: uniform) -> TfmType.Coord:\n",
    "    return x.add_((torch.rand_like(x)-0.5)*magnitude*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = jitter_tfm(magnitude=(0,0.1))\n",
    "\n",
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_tfms(tfm)(x), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@reg_transform\n",
    "def flip_lr(x) -> TfmType.Pixel: return x.flip(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = flip_lr_tfm(p=0.5)\n",
    "\n",
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_tfms(tfm)(x), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [flip_lr_tfm(p=0.5),\n",
    "        rotate_tfm(degrees=(-45,45.), p=0.5),\n",
    "        zoom_tfm(scale=(0.6,1.6), p=0.8),\n",
    "        contrast_tfm(scale=(0.5,2.0)),\n",
    "        brightness_tfm(change=(0.3,0.7))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_tfms(tfms)(x), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(2,4, figsize=(12,6))\n",
    "for i in range(4):\n",
    "    tfm = apply_tfms(tfms)\n",
    "    show_image(tfm(x, padding_mode='zeros', size=48), axes[0][i])\n",
    "    show_image(tfm(x, mode='nearest'), axes[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
