{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A basic training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the last notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip, torch, math, numpy as np, torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from dataclasses import dataclass\n",
    "\n",
    "#support type hints\n",
    "from typing import Any, Collection, Callable, NewType, List, Union, TypeVar, Optional\n",
    "\n",
    "from functools import partial, reduce\n",
    "from numbers import Number\n",
    "\n",
    "from numpy import array\n",
    "from torch import nn, optim, tensor, Tensor\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the MNIST training images and labels**\n",
    "\n",
    "The data is downloaded in notebook *_001a_nn_basics* so make sure you have run through that notebook first.\n",
    "\n",
    "We print out the min and max of the features to get a feel for the range of feature values. In the case of the MNIST dataset, the features for a specific training example correspond to pixel values that, as we can see, range from 0 to ~1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.9961))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "PATH = DATA_PATH/'mnist'\n",
    "\n",
    "with gzip.open(PATH/'mnist.pkl.gz', 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "\n",
    "x_train,y_train,x_valid,y_valid = map(torch.tensor, (x_train,y_train,x_valid,y_valid))\n",
    "x_train.min(),x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([166, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].nonzero().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the batch size, number of epochs and learning rate**\n",
    "\n",
    "The fast.ai library uses lots of abbreviations so as to make the code more concise. A reference for abbreviations can be found [here](https://github.com/fastai/fastai_v1/blob/master/docs/abbr.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64\n",
    "epochs = 2\n",
    "lr=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the training and validation datasets**\n",
    "\n",
    "In this case we are passing in two tensors: training features and classification targets.\n",
    "So each iteration of the TensorDataset will return a tuple of length two with the following form: (x_features, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524313"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# newtype type check\n",
    "UserId= NewType('UserId', int)\n",
    "UserId(524313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank0Tensor = NewType('OneEltTensor', Tensor)\n",
    "LossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\n",
    "Model = nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_listy(x:Any)->bool: return isinstance(x, (tuple,list))\n",
    "\n",
    "def loss_batch(model, xb, yb, loss_fn, opt=None):\n",
    "    loss = loss_fn(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs:int, model:Model, loss_fn:LossFunction, \n",
    "        opt:optim.Optimizer, train_dl:DataLoader, valid_dl:DataLoader):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in train_dl: loss_batch(model, xb, yb, loss_fn, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses,nums = zip(*[loss_batch(model, xb, yb, loss_fn)\n",
    "                                for xb,yb in valid_dl])\n",
    "        val_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func=func\n",
    "        \n",
    "    def forward(self, x): return self.func(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify nn.Sequential layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Composition** \n",
    "\n",
    "Function composition is a great way to capture and parameterize common operations as a single concept. You can see this with the *PoolFlatten* function below.\n",
    "\n",
    "The *Lambda* layer we created in the last notebook makes it easy to quickly create Pytorch layers for different purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ResizeBatch(*size): return Lambda(lambda x: x.view((-1,)+size))\n",
    "def Flatten(): return Lambda(lambda x: x.view((x.size(0), -1)))\n",
    "def PoolFlatten(): \n",
    "    \"Apply `nn.AdaptiveAvgPool2d` to `x` and then flatten the result\"\n",
    "    return nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the model**\n",
    "\n",
    "Thanks to our named Pytorch nn.Modules above, the meaning and intention of each of the layers in our model is clearer and less prone to error when we make changes.\n",
    "\n",
    "On kernel size: We will nearly always use small kernels of size 3 due to the reasons presented in section 2.3 in [this](https://arxiv.org/pdf/1409.1556.pdf) paper (mainly a few small kernels achieve a receptive field of the same dimension as one bigger kernel while at the same time achieving increased discriminative power and using fewer parameters). \n",
    "\n",
    "Next we have a stripped down CNN example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    ResizeBatch(1,28,28),\n",
    "    nn.Conv2d(1,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    PoolFlatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a *get_data* function**\n",
    "\n",
    "It's often conventient to define a *get_data* function that encapsulates the work of setting up the training, validation and sometimes test data. Parameterizing *get_data* makes it easy to do things like change the batch size, etc.\n",
    "\n",
    "Notice in this scenario that we shuffle the training dataloader but not the validation dataloader. We want the validation loss to be calculated the same way every time so that we can tell if we are still learning and not overfitting. Shuffling the training data helps prevent overfitting when calculating the gradients to be applied after each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "            DataLoader(valid_ds, batch_size=bs*2))\n",
    "\n",
    "train_dl,valid_dl = get_data(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set loss function**\n",
    "\n",
    "[Here](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/) is tutorial explaining why cross entropy is a resonable loss function for classifciation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set optimizer**\n",
    "\n",
    "We stick with stochastic gradient descent without momentum as our optimizer. This is a basic optimizer and it is [easy to understand](http://ruder.io/optimizing-gradient-descent/index.html#stochasticgradientdescent). We will move into better optimizers as we go forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test our loss function**\n",
    "\n",
    "We try out our loss function on one batch of X features and y targets to make sure it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3037, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model(x_valid[0:bs]), y_valid[0:bs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit**\n",
    "\n",
    "Everything looks ready, we call the fit function we developed earlier for two epochs to confirm that the model learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.43291589860916135\n",
      "1 0.6470388515472412\n",
      "2 0.3106609450340271\n",
      "3 0.27235843381881714\n",
      "4 0.42025797719955443\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to refactor some of the data transformations out of the network and into a pipeline that is applied to the data being fed into the Dataloders.\n",
    "\n",
    "This is more flexible, simplifies the model, and will be useful later when we want to apply additional transformations for things like data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define transformations**\n",
    "\n",
    "In this example our only transformation will be *mnist2image*. This is a utility function to reshape our features into 28x28 arrays.\n",
    "\n",
    "X is a batch of features where the first dimension is the number of samples in the batch and the remaining dimensions define the shape of the training example. y is the target variable to be learned, in this case it an integer representing one of 10 image classes.\n",
    "\n",
    "With MNIST data, the X features start out as a 1x784 vector and we want to convert the features to 1x28x28 images (see line 62). This helper function does that for an entire batch of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist2image(b): return b.view(1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to this\n",
    "```\n",
    "class FMNIST(Dataset):\n",
    "    def __init__(self,X,y,transforms=None):\n",
    "        self.X = X[:,:,:,None] # n,28,28 to n,28,28,1\n",
    "        self.y = y\n",
    "        self.n = len(X)\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img = self.X[index]\n",
    "        label = self.y[index]\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return (img,label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# @dataclass\n",
    "# class TfmDataset(Dataset):\n",
    "#     ds: Dataset\n",
    "#     tfm: Callable = None\n",
    "        \n",
    "#     def __len__(self): return len(self.ds)\n",
    "    \n",
    "#     def __getitem__(self,idx):\n",
    "#         x,y = self.ds[idx]\n",
    "#         if self.tfm is not None: x = self.tfm(x)\n",
    "#         return x,y\n",
    "    \n",
    "class TfmDataset(Dataset):\n",
    "    def __init__(self,ds,tfm=None):\n",
    "        self.ds = ds\n",
    "        self.tfm = tfm\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x,y = self.ds[idx]\n",
    "        if self.tfm is not None: x = self.tfm(x)\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tds = TfmDataset(train_ds, mnist2image)\n",
    "valid_tds = TfmDataset(valid_ds, mnist2image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (DataLoader(train_tds, bs,   shuffle=True),\n",
    "            DataLoader(valid_tds, bs*2, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,valid_dl = get_data(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make some checks to make sure that *mnist2image* is working correctly:\n",
    "1. The input and output shapes are as expected\n",
    "2. The input and output data (features) are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1, 28, 28]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0][0].shape, x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(valid_ds[0][0], x[0].view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define layer types and loop over them**\n",
    "\n",
    "When use a layer type more than once in a contiguous fashion (one after the other), it makes sense to define a function for that layer type and then use that function to build our model function. \n",
    "\n",
    "That is what we do here with *conv2_relu* with which we avoid the three subsequent lines of code in line 12 (this saving becomes more significant in deeper networks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(ni:int, nf:int, ks:int=3, stride:int=1, padding:int=None, bias=False) -> nn.Conv2d:\n",
    "    \"Create `nn.Conv2d` layer: `ni` inputs, `nf` outputs, `ks` kernel size. `padding` defaults to `k//2`\"\n",
    "    if padding is None: padding = ks//2\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=padding, bias=bias)\n",
    "\n",
    "def conv2d_relu(ni:int, nf:int, ks:int=3, stride:int=1, \n",
    "                padding:int=None, bn:bool=False) -> nn.Sequential:\n",
    "    \"Create a `conv2d` layer with `nn.ReLU` activation and optional(`bn`) `nn.BatchNorm2d`\"\n",
    "    layers = [conv2d(ni, nf, ks=ks, stride=stride, padding=padding), nn.ReLU()]\n",
    "    if bn: layers.append(nn.BatchNorm2d(nf))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv2d_trans(ni:int, nf:int, ks:int=2, stride:int=2, padding:int=0) -> nn.ConvTranspose2d:\n",
    "    \"Create `nn.nn.ConvTranspose2d` layer: `ni` inputs, `nf` outputs, `ks` kernel size. `padding` defaults to 0\"\n",
    "    return nn.ConvTranspose2d(ni, nf, kernel_size=ks, stride=stride, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# def conv2_relu(nif, nof, ks, stride):\n",
    "#     return nn.Sequential(nn.Conv2d(nif, nof, ks, stride, padding=ks//2), nn.ReLU())\n",
    "\n",
    "def simple_cnn(actns, kernel_szs, strides):\n",
    "    layers = [conv2d_relu(actns[i], actns[i+1], kernel_szs[i], stride=strides[i])\n",
    "        for i in range(len(strides))]\n",
    "    layers.append(PoolFlatten())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = simple_cnn([1,16,16,10], [3,3,3], [2,2,2])\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4467840166091919\n",
      "1 0.5012163402557374\n",
      "CPU times: user 19.6 s, sys: 1.09 s, total: 20.7 s\n",
      "Wall time: 9.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run in GPU and add progress bar**\n",
    "\n",
    "To run our Pytorch networks in the GPU we have to specify it in the code. This is done by setting *torch.device('cuda')*. We will also add a progress bar to keep track of the progress during training. This we acomplish with the *tqdm_notebook* module of the [tqdm](https://github.com/tqdm/tqdm) package.\n",
    "\n",
    "We integrate both these features into a custom Dataloader which we build on top of the Pytorch Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# from tqdm import tqdm, tqdm_notebook, trange, tnrange\n",
    "# from ipykernel.kernelapp import IPKernelApp\n",
    "\n",
    "# def in_notebook(): return IPKernelApp.initialized()\n",
    "\n",
    "# def to_device(device, b): return [o.to(device) for o in b]\n",
    "# default_device = torch.device('cuda')\n",
    "\n",
    "# if in_notebook():\n",
    "#     tqdm = tqdm_notebook\n",
    "#     trange = tnrange\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class DeviceDataLoader():\n",
    "#     '''\n",
    "#     Custom Data Loader (GPU training + tqdm progress bar)\n",
    "#     '''\n",
    "#     def __init__(self,dl,device,progress_func = None):\n",
    "#         self.dl,self.device,self.progress_func = dl,device,progress_func\n",
    "        \n",
    "#     def __len__(self): return len(self.dl)\n",
    "#     def __iter__(self):\n",
    "#         self.gen = (to_device(self.device,o) for o in self.dl) # each o is (X,y), and will turn into [X in cuda, y in cuda]\n",
    "#         if self.progress_func is not None:\n",
    "#             self.gen = self.progress_func(self.gen, total=len(self.dl), leave=False)\n",
    "#         return iter(self.gen)\n",
    "\n",
    "\n",
    "#     '''\n",
    "#     Return DeviceDataLoader obj\n",
    "#     '''\n",
    "#     @classmethod\n",
    "#     def create(cls, *args, device=default_device, progress_func=tqdm, **kwargs):\n",
    "#         return cls(DataLoader(*args, **kwargs), device=device, progress_func=progress_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ifnone(a:bool,b:Any):\n",
    "    \"`a` if its not None, otherwise `b`\"\n",
    "    return b if a is None else a\n",
    "\n",
    "default_device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "Tensors = Union[Tensor, Collection['Tensors']]\n",
    "\n",
    "def to_device(b:Tensors, device:torch.device):\n",
    "    \"Ensure `b` is on `device`\"\n",
    "    device = ifnone(device, default_device)\n",
    "    if is_listy(b): return [to_device(o, device) for o in b]\n",
    "    return b.to(device)\n",
    "\n",
    "@dataclass\n",
    "class DeviceDataLoader():\n",
    "    \"`DataLoader` that ensures batches from `dl` are on `device`\"\n",
    "    dl: DataLoader\n",
    "    device: torch.device\n",
    "\n",
    "    def __len__(self) -> int: return len(self.dl)\n",
    "    def proc_batch(self,b:Tensors): return to_device(b, self.device)\n",
    "\n",
    "    def __iter__(self)->Tensors:\n",
    "        \"Ensure batches from `dl` are on `device` as we iterate\"\n",
    "        self.gen = map(self.proc_batch, self.dl)\n",
    "        return iter(self.gen)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, *args, device:torch.device=default_device, **kwargs): \n",
    "        return cls(DataLoader(*args, **kwargs), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (DeviceDataLoader.create(train_tds, bs,   shuffle=True),\n",
    "            DeviceDataLoader.create(valid_tds, bs*2, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,valid_dl = get_data(train_tds, valid_tds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fit(epochs:int, model:Model, loss_fn:LossFunction, \n",
    "        opt:optim.Optimizer, train_dl:DataLoader, valid_dl:DataLoader) -> None:\n",
    "    \"Train `model` for `epochs` with `loss_fun` and `optim`\"\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in train_dl: loss,_ = loss_batch(model, xb, yb, loss_fn, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses,nums = zip(*[loss_batch(model, xb, yb, loss_fn)\n",
    "                                for xb,yb in valid_dl])\n",
    "        val_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = simple_cnn([1,16,16,10], [3,3,3], [2,2,2]).to(default_device)\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9289371654510498\n",
      "1 0.7716784593105316\n",
      "2 0.5402628433704376\n",
      "3 0.6262347139358521\n",
      "4 0.2591162664413452\n",
      "CPU times: user 8.47 s, sys: 340 ms, total: 8.81 s\n",
      "Wall time: 9.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define learner**\n",
    "\n",
    "Finally, we are missing a learner class to close the gap between our loaded data and our model. The learner class will receive our loaded data (after transformations) and the model and we will be able to call fit on it to start the training phase.\n",
    "\n",
    "Note that we must define another fit function to track the progress of our training with the progress bar we included in the Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# def fit(epochs, model, loss_fn, opt, train_dl, valid_dl):\n",
    "#     for epoch in tnrange(epochs):\n",
    "#         model.train()\n",
    "#         for xb,yb in train_dl:\n",
    "#             loss,_ = loss_batch(model, xb, yb, loss_fn, opt)\n",
    "#             if train_dl.progress_func is not None: train_dl.gen.set_postfix_str(loss)\n",
    "\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             losses,nums = zip(*[loss_batch(model, xb, yb, loss_fn)\n",
    "#                                 for xb,yb in valid_dl])\n",
    "#         val_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "\n",
    "#         print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# class DataBunch():\n",
    "#     def __init__(self, train_ds, valid_ds, bs=64, device=None, train_tfm=None, valid_tfm=None):\n",
    "#         self.device = default_device if device is None else device\n",
    "#         self.train_dl = DeviceDataLoader.create(TfmDataset(train_ds,train_tfm), bs, shuffle=True)\n",
    "#         self.valid_dl = DeviceDataLoader.create(TfmDataset(valid_ds, valid_tfm), bs*2, shuffle=False)\n",
    "        \n",
    "\n",
    "# class Learner():\n",
    "#     '''\n",
    "#     Encapsulate data (dataloader) and model, also to fit model given opt,loss fn, lr,epochs ...\n",
    "#     '''\n",
    "#     def __init__(self, data, model):\n",
    "#         self.data,self.model = data,model.to(data.device)\n",
    "\n",
    "#     def fit(self, epochs, lr, opt_fn=optim.SGD):\n",
    "#         opt = opt_fn(self.model.parameters(), lr=lr)\n",
    "#         loss_fn = F.cross_entropy\n",
    "#         fit(epochs, self.model, loss_fn, opt, self.data.train_dl, self.data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "TItem = TypeVar('TItem')\n",
    "TfmCallable = Callable[[TItem],TItem]\n",
    "TfmList = Union[TfmCallable, Collection[TfmCallable]]\n",
    "Tfms = Optional[TfmList]\n",
    "\n",
    "@dataclass\n",
    "class DataBunch():\n",
    "    \"Bind `train_dl`, `valid_dl` to `device`\"\n",
    "    train_dl:DataLoader\n",
    "    valid_dl:DataLoader\n",
    "    device:torch.device=None\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, train_ds:Dataset, valid_ds:Dataset, bs:int=64, \n",
    "               train_tfm:Tfms=None, valid_tfm:Tfms=None, device:torch.device=None, **kwargs):\n",
    "        return cls(DeviceDataLoader.create(TfmDataset(train_ds, train_tfm), bs,   \n",
    "                                           shuffle=True,  device=device, **kwargs),\n",
    "                   DeviceDataLoader.create(TfmDataset(valid_ds, valid_tfm), bs*2, \n",
    "                                           shuffle=False, device=device, **kwargs),\n",
    "                   device=device)\n",
    "\n",
    "class Learner():\n",
    "    \"Train `model` on `data` for `epochs` using learning rate `lr` and `opt_fn` to optimize training\"\n",
    "    def __init__(self, data:DataBunch, model:Model):\n",
    "        self.data,self.model = data,to_device(model, data.device)\n",
    "\n",
    "    def fit(self, epochs, lr, opt_fn=optim.SGD):\n",
    "        opt = opt_fn(self.model.parameters(), lr=lr)\n",
    "        loss_fn = F.cross_entropy\n",
    "        fit(epochs, self.model, loss_fn, opt, self.data.train_dl, self.data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch.create(train_ds, valid_ds, bs=bs, train_tfm=mnist2image, valid_tfm=mnist2image)\n",
    "model = simple_cnn([1,16,16,10], [3,3,3], [2,2,2])\n",
    "learner = Learner(data, model)\n",
    "opt_fn = partial(optim.SGD, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.457115455532074\n",
      "1 0.3451181959152222\n",
      "2 0.2594533142089844\n",
      "3 0.2409851318359375\n"
     ]
    }
   ],
   "source": [
    "learner.fit(4, lr/5, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(data, simple_cnn([1,16,16,10], [3,3,3], [2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(1, lr/5, opt_fn=opt_fn)\n",
    "learner.fit(2, lr, opt_fn=opt_fn)\n",
    "learner.fit(1, lr/5, opt_fn=opt_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
